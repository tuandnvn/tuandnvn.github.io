{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hackerrank.com/challenges/dota2prediction/problem\n",
    "\n",
    "Gabe and his 9 friends enjoy playing a video game called Defence of the Ancients. This game consists of two 5-player teams fighting each other on a virtual battlefield.\n",
    "\n",
    "Before the game starts, each player picks a virtual hero as their character from a pool of about 100 heroes. Each hero can only be picked by one player in a game. Gabe and his friends are very similar in skill-level, so the outcome of their games has some dependence on which heroes were chosen. Gabe wonders if he can predict the outcome of a game based on what heroes have been picked.\n",
    "\n",
    "*** Game Data ***\n",
    "\n",
    "Gabe has extensive records of past games between similar players. You can download this training data with the results of 15,000 games that Gabe has already played. You need to analyze the data to find trends about each hero. Hero names contain spaces, apostrophes, and hyphens.\n",
    "\n",
    "The data consists of 15,000 lines, each with 10 strings and one number all seperated by commas. On each line, the first 5 strings are the heroes picked by team 1, the second 5 strings are the heroes picked by the team 2, and the number at the end is the number of the team who won.\n",
    "\n",
    "*** Challenge ***\n",
    "\n",
    "In each of K games, you will be given the heroes picked by each team. Using the training data, can you predict which team will win based on the heroes that they have picked? You will be scored based on how many predictions you get right. You may access the trainingdata by reading from the file \"trainingdata.txt\".\n",
    "\n",
    "*** Input ***\n",
    "\n",
    "The first line will contain a single integer K, the number of games you need to predict. This is followed by K lines containing 10 comma separated strings of the 10 chosen heroes.\n",
    "\n",
    "*** Output ***\n",
    "\n",
    "For each game, output the number (1 or 2) of the team you think will win on a new line.\n",
    "\n",
    "*** Constraints ***\n",
    "\n",
    "1 ≤ K ≤ 3000\n",
    "\n",
    "*** Sample Input ***\n",
    "\n",
    "5\n",
    "\n",
    "Spectre,Nature's Prophet,Ogre Magi,Nyx Assassin,Kunkka,Lone Druid,Windrunner,Disruptor,Juggernaut,Naga Siren\n",
    "\n",
    "Windrunner,Medusa,Zeus,Shadow Fiend,Troll Warlord,Bounty Hunter,Pudge,Lycanthrope,Riki,Pugna\n",
    "\n",
    "Ogre Magi,Sniper,Rubick,Lifestealer,Treant Protector,Slardar,Lion,Shadow Fiend,Weaver,Nature's Prophet\n",
    "\n",
    "Sniper,Nyx Assassin,Lich,Axe,Necrolyte,Magnus,Juggernaut,Dazzle,Tinker,Nature's Prophet\n",
    "\n",
    "Lina,Nature's Prophet,Chaos Knight,Gyrocopter,Invoker,Sven,Broodmother,Necrolyte,Undying,Windrunner\n",
    "\n",
    "\n",
    "*** Sample Output ***\n",
    "\n",
    "1\n",
    "1\n",
    "1\n",
    "1\n",
    "1\n",
    "\n",
    "*** Scoring ***\n",
    "\n",
    "Your score for this challenge will based on what percentage of your predictions are correct, according to this formula:\n",
    "\n",
    "Score = 100 * ((#correct - #incorrect) / total)\n",
    "\n",
    "If you are are correct for less than half the games, you will receive a score of 0. Your score will only be based on the second (hidden) test case. The sample test case is just for checking if your program is working as intended in our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.len = 0\n",
    "    \n",
    "    def add (self,word):\n",
    "        if word in self.vocab:\n",
    "            return\n",
    "        \n",
    "        self.vocab[word] = self.len\n",
    "        self.len += 1\n",
    "        \n",
    "    def isIn(self, word):\n",
    "        return word in self.vocab\n",
    "        \n",
    "    def get_index ( self, word ):\n",
    "        return self.vocab[word]\n",
    "    \n",
    "    def get_word ( self, index ) :\n",
    "        if 'invert' not in self.__dict__:\n",
    "            self.invert = dict((v,k) for k, v in self.vocab.items())\n",
    "        return self.invert[index]\n",
    "        \n",
    "vocab = Vocabulary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('trainingdata.txt', 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    # Phantom Lancer,Chaos Knight,Warlock,Venomancer,Batrider,Ogre Magi,Clinkz,Anti-Mage,Ursa,Bane,1\n",
    "    for line in lines:\n",
    "        parts = line.split(',')\n",
    "        \n",
    "        for word in parts[:10]:\n",
    "            vocab.add(word)\n",
    "            \n",
    "        team_1 = [vocab.get_index(word) for word in parts[:5]]\n",
    "        team_2 = [vocab.get_index(word) for word in parts[5:10]]\n",
    "        result = int(parts[10])\n",
    "        \n",
    "        matches.append((team_1, team_2, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 76, 32, 68, 82], [21, 29, 24, 16, 54], 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ranking different kinds of features\n",
    "# By calculating mutual information for each feature\n",
    "\n",
    "# Single features\n",
    "# Simple, just using sklearn to select single features\n",
    "# A 2x|V| vector is created, as two one-hot vector concatenation\n",
    "\n",
    "\n",
    "# Binary features\n",
    "# Create binary features, and then using sklearn to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(matches), vocab.len ))\n",
    "Y = np.zeros(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, match in enumerate(matches):\n",
    "    team_1, team_2, result = match\n",
    "    for v in team_1:\n",
    "        X[i][v] = 1\n",
    "    for v in team_2:\n",
    "        X[i][v] = -1\n",
    "    Y[i] = result-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's blindly apply some machine learning algorithm out of the box, to see how well they perform on this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Logistic regression **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.602066666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Linear Discriminant Analysis **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are a lots of *collinear warning* when we trained with LDA. As far as the performance goes, we can see that the performance of these two methods are pretty close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** K-nearest neighbors **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a34d6e6ede66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \"\"\"\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[0;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 385\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m             )\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow-cpu\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with K-nearest neighbors is obviously the curse of dimensionality, we have a very high number of dimension here, so the distance between any two data points is nearly the same everywhere. Moreover, as our data is binary, K-nearest neighbor is not really a good choice anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Naive Bayes ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567266666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we achive a performance comparable to LR and LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SVM **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594533333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bagged decision tree ** \n",
    "\n",
    "We would also try an ensemble method employing decision tree as base estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533466666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cart = DecisionTreeClassifier(criterion = 'entropy')\n",
    "num_trees = 10\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7, max_samples = 0.5, max_features=0.5)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic_coef = [ 0.81677673,  0.57499219,  0.45694456,  0.34542858,  0.35697136,\n",
    "         0.25042017,  0.28351395,  0.2347544 ,  0.20150746,  0.18919355,\n",
    "         0.22454607,  0.22966371,  0.229111  ,  0.20464181,  0.18805431,\n",
    "        -0.22979506, -0.20754391, -0.22435342, -0.21644672, -0.26578194,\n",
    "        -0.23921589, -0.3082163 , -0.30379924, -0.30825253, -0.35380314,\n",
    "        -0.30692574, -0.35971862, -0.38457256, -0.41606547, -0.45076123,\n",
    "        -0.73790523, -0.63810305, -0.50621481, -0.49943388, -0.40936881,\n",
    "        -0.30463815, -0.28971389, -0.31520699, -0.28108395, -0.27297841,\n",
    "        -0.23743515, -0.23468561, -0.20902621, -0.24810791, -0.2058793 ,\n",
    "         0.18931256,  0.21837809,  0.19669076,  0.23303521,  0.26475739,\n",
    "         0.24176284,  0.25048168,  0.2001663 ,  0.31128437,  0.25171945,\n",
    "         0.25122132,  0.32045726,  0.37789383,  0.44938722,  0.50260205]\n",
    "\n",
    "logistic_intercept = -0.02959285\n",
    "\n",
    "vocab = {'Alchemist': 8,\n",
    "  'Ancient Apparition': 77,\n",
    "  'Anti-Mage': 7,\n",
    "  'Axe': 90,\n",
    "  'Bane': 38,\n",
    "  'Batrider': 65,\n",
    "  'Beastmaster': 67,\n",
    "  'Bloodseeker': 88,\n",
    "  'Bounty Hunter': 54,\n",
    "  'Brewmaster': 48,\n",
    "  'Broodmother': 31,\n",
    "  'Centaur Warrunner': 29,\n",
    "  'Chaos Knight': 66,\n",
    "  'Chen': 61,\n",
    "  'Clinkz': 74,\n",
    "  'Clockwerk': 3,\n",
    "  'Crystal Maiden': 45,\n",
    "  'Dark Seer': 47,\n",
    "  'Dazzle': 58,\n",
    "  'Death Prophet': 84,\n",
    "  'Disruptor': 50,\n",
    "  'Doom': 56,\n",
    "  'Dragon Knight': 80,\n",
    "  'Drow Ranger': 34,\n",
    "  'Earthshaker': 55,\n",
    "  'Enchantress': 85,\n",
    "  'Enigma': 53,\n",
    "  'Faceless Void': 27,\n",
    "  'Gyrocopter': 6,\n",
    "  'Huskar': 57,\n",
    "  'Invoker': 5,\n",
    "  'Jakiro': 73,\n",
    "  'Juggernaut': 51,\n",
    "  'Keeper of the Light': 23,\n",
    "  'Kunkka': 36,\n",
    "  'Leshrac': 13,\n",
    "  'Lich': 86,\n",
    "  'Lifestealer': 82,\n",
    "  'Lina': 46,\n",
    "  'Lion': 64,\n",
    "  'Lone Druid': 1,\n",
    "  'Luna': 69,\n",
    "  'Lycanthrope': 93,\n",
    "  'Magnus': 22,\n",
    "  'Medusa': 94,\n",
    "  'Meepo': 42,\n",
    "  'Mirana': 20,\n",
    "  'Morphling': 43,\n",
    "  'Naga Siren': 59,\n",
    "  \"Nature's Prophet\": 60,\n",
    "  'Necrolyte': 18,\n",
    "  'Night Stalker': 96,\n",
    "  'Nyx Assassin': 14,\n",
    "  'Ogre Magi': 49,\n",
    "  'Omniknight': 44,\n",
    "  'Outworld Devourer': 87,\n",
    "  'Phantom Assassin': 75,\n",
    "  'Phantom Lancer': 70,\n",
    "  'Puck': 12,\n",
    "  'Pudge': 21,\n",
    "  'Pugna': 91,\n",
    "  'Queen of Pain': 26,\n",
    "  'Razor': 35,\n",
    "  'Riki': 10,\n",
    "  'Rubick': 24,\n",
    "  'Sand King': 16,\n",
    "  'Shadow Demon': 95,\n",
    "  'Shadow Fiend': 76,\n",
    "  'Shadow Shaman': 4,\n",
    "  'Silencer': 41,\n",
    "  'Skeleton King': 81,\n",
    "  'Slardar': 15,\n",
    "  'Slark': 9,\n",
    "  'Sniper': 28,\n",
    "  'Spectre': 17,\n",
    "  'Spirit Breaker': 89,\n",
    "  'Storm Spirit': 72,\n",
    "  'Sven': 0,\n",
    "  'Templar Assassin': 79,\n",
    "  'Tidehunter': 25,\n",
    "  'Timbersaw': 40,\n",
    "  'Tinker': 11,\n",
    "  'Tiny': 52,\n",
    "  'Treant Protector': 30,\n",
    "  'Troll Warlord': 33,\n",
    "  'Undying': 83,\n",
    "  'Ursa': 62,\n",
    "  'Vengeful Spirit': 92,\n",
    "  'Venomancer': 2,\n",
    "  'Viper': 78,\n",
    "  'Visage': 39,\n",
    "  'Warlock': 19,\n",
    "  'Weaver': 32,\n",
    "  'Windrunner': 68,\n",
    "  'Wisp': 63,\n",
    "  'Witch Doctor': 71,\n",
    "  'Zeus': 37}\n",
    "\n",
    "f_for_first = dict((k, i) for i, k in enumerate([42, 40, 94, 31, 7, 75, 43, 8, 52, 5, 87, 57, 79, 1, 28, 16, 29, 96, 86, 73, 33, 89, 92, 37, 23, 70, 34, 14, 19, 69]))\n",
    "f_for_second = dict((k, i) for i, k in enumerate([42, 31, 94, 75, 43, 40, 85, 8, 5, 7, 28, 74, 90, 56, 59, 9, 62, 23, 86, 3, 63, 92, 69, 29, 89, 70, 37, 19, 39, 14]))\n",
    "\n",
    "lines = sys.stdin.readlines()\n",
    "\n",
    "for line in lines[1:]:\n",
    "    parts = line.strip().split(',')\n",
    "    \n",
    "    team_1 = [vocab[word] for word in parts[:5]]\n",
    "    team_2 = [vocab[word] for word in parts[5:10]]\n",
    "    \n",
    "    u_1 = []\n",
    "    u_2 = []\n",
    "    \n",
    "    for q in team_1:\n",
    "        if q in f_for_first:\n",
    "            u_1.append(f_for_first[q])\n",
    "    \n",
    "    for q in team_2:\n",
    "        if q in f_for_second:\n",
    "            u_2.append(f_for_second[q])\n",
    "    \n",
    "    t = logistic_intercept\n",
    "    for q in u_1:\n",
    "        t += logistic_coef[q] \n",
    "    \n",
    "    for q in u_2:\n",
    "        t += logistic_coef[q + 30] \n",
    "    \n",
    "    if t > 0:\n",
    "        print (1)\n",
    "    else:\n",
    "        print (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is, not suprisingly, bad. The reason would be explained a little bit later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, our performance has been mediocre. We can see one of the problem is that our data has two many dimensions, a few things we can do to improve it:\n",
    "\n",
    "- Reduce number of dimensions by feature selection methods\n",
    "\n",
    "- Reduce number of dimensions by data reduction techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Univariate selection **\n",
    "\n",
    "This is a principle in feature selection, basically saying that you should consider each feature's predictive power independently. Therefore, we would test statistic significance of a feature regarding to predicting labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=40,\n",
       "      score_func=<function mutual_info_classif at 0x000001EEDEBE6F28>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SelectKBest(mutual_info_classif, k = 40)\n",
    "s.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_r = s.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this transformed data with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535666666667\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X_r, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What, why is that? We hope that the performance would be improved, but in fact, it is even worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = s.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature for first side 2 Venomancer\n",
      "Feature for first side 3 Clockwerk\n",
      "Feature for first side 5 Invoker\n",
      "Feature for first side 11 Tinker\n",
      "Feature for first side 17 Spectre\n",
      "Feature for first side 23 Keeper of the Light\n",
      "Feature for first side 65 Batrider\n",
      "Feature for first side 72 Storm Spirit\n",
      "Feature for first side 81 Skeleton King\n",
      "Feature for first side 86 Lich\n",
      "Feature for first side 87 Outworld Devourer\n",
      "Feature for first side 91 Pugna\n",
      "Feature for second side 120 Keeper of the Light\n",
      "Feature for second side 122 Tidehunter\n",
      "Feature for second side 127 Treant Protector\n",
      "Feature for second side 131 Drow Ranger\n",
      "Feature for second side 141 Omniknight\n",
      "Feature for second side 150 Enigma\n",
      "Feature for second side 178 Skeleton King\n",
      "Feature for second side 184 Outworld Devourer\n"
     ]
    }
   ],
   "source": [
    "for v in np.argwhere(t == True).flatten():\n",
    "    if v < vocab.len:\n",
    "        print ('Feature for first side ' + str(v) + ' ' + vocab.get_word(v))\n",
    "    else:\n",
    "        print ('Feature for second side ' + str(v) + ' ' + vocab.get_word(v - vocab.len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_for_feature(v):\n",
    "    # Count number of times this feature appears in the team, number of win\n",
    "    total = 0\n",
    "    win = 0\n",
    "    \n",
    "    for i, match in enumerate(matches):\n",
    "        team_1, team_2, result = match\n",
    "        \n",
    "        if v < vocab.len:\n",
    "            # First side\n",
    "            team = team_1\n",
    "            d = 1\n",
    "            f = vocab.get_word(v)\n",
    "            included = v in team\n",
    "        else:\n",
    "            team = team_2\n",
    "            d = 2\n",
    "            f = vocab.get_word(v - vocab.len)\n",
    "            included =  v - vocab.len in team\n",
    "        \n",
    "        if included:\n",
    "            total += 1\n",
    "        \n",
    "            if result == 1 and v < vocab.len:\n",
    "                win += 1\n",
    "            if result == 2 and v >= vocab.len: \n",
    "                win += 1\n",
    "    # print ('Total number of match that team %d picks %s = %d, number of wins = %d, percentage = %.1f%%' % (d, f, total, win, win*100/total))\n",
    "    return total, win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let do a double check on the feature. We know that a hero is good if most of the time we have that hero in our team, we won and vice versa. So let's do a check on a few heroes we have here.\n",
    "\n",
    "Let's start with Venomancer, indexed at 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of match that team 1 picks Tinker = 690, number of wins = 348, percentage = 50.4%\n"
     ]
    }
   ],
   "source": [
    "total, win = stat_for_feature(11)\n",
    "print ('Total number of match that team %d picks %s = %d, number of wins = %d, percentage = %.1f%%' % (1, 'Tinker', total, win, win*100/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what. There seems to be no correlation between using of this hero with the winning percentage, why it even shows up here.\n",
    "\n",
    "It turned out that when the mutual information is calculated, you actually account for both label of the feature, so mutual information encompasses the information you gain when the feature is **missing**. That is probably not a good indicator, so I think we should use win the winning percentage as quality indicator of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_first_team = []\n",
    "for i in range(vocab.len):\n",
    "    total, win = stat_for_feature(i)\n",
    "    features_for_first_team.append((i, total, win))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_second_team = []\n",
    "for i in range(vocab.len, 2 * vocab.len):\n",
    "    total, win = stat_for_feature(i)\n",
    "    features_for_second_team.append((i- vocab.len, total, win))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the correlation between two variables, the first variable is the possibility of winning (strength) of each hero for the first team, and the second variable is for the second team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.86688668],\n",
       "       [ 0.86688668,  1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = [win/total for _, total, win in features_for_first_team]\n",
    "v2 = [win/total for _, total, win in features_for_second_team]\n",
    "np.corrcoef(np.array([v1, v2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(v1, v2) =  0.9896633. They are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_first_team = sorted(features_for_first_team, key = lambda a : a[2] / a[1])\n",
    "features_for_second_team= sorted(features_for_second_team, key = lambda a : a[2] / a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 best predictors for first team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature = Meepo, winning percentage = 32.6%\n",
      "Feature = Timbersaw, winning percentage = 38.4%\n",
      "Feature = Medusa, winning percentage = 41.6%\n",
      "Feature = Broodmother, winning percentage = 43.7%\n",
      "Feature = Anti-Mage, winning percentage = 44.4%\n",
      "Feature = Phantom Assassin, winning percentage = 45.4%\n",
      "Feature = Morphling, winning percentage = 45.4%\n",
      "Feature = Alchemist, winning percentage = 46.0%\n",
      "Feature = Tiny, winning percentage = 47.1%\n",
      "Feature = Invoker, winning percentage = 47.3%\n",
      "Feature = Troll Warlord, winning percentage = 57.5%\n",
      "Feature = Spirit Breaker, winning percentage = 58.8%\n",
      "Feature = Vengeful Spirit, winning percentage = 59.0%\n",
      "Feature = Zeus, winning percentage = 59.5%\n",
      "Feature = Keeper of the Light, winning percentage = 60.0%\n",
      "Feature = Phantom Lancer, winning percentage = 60.4%\n",
      "Feature = Drow Ranger, winning percentage = 60.6%\n",
      "Feature = Nyx Assassin, winning percentage = 61.2%\n",
      "Feature = Warlock, winning percentage = 62.1%\n",
      "Feature = Luna, winning percentage = 62.4%\n"
     ]
    }
   ],
   "source": [
    "for i, total, win in features_for_first_team[:10] + features_for_first_team[-10:]:\n",
    "    print ('Feature = %s, winning percentage = %.1f%%' % (vocab.get_word(i), win*100/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 best predictors for second team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature = Meepo, winning percentage = 31.6%\n",
      "Feature = Broodmother, winning percentage = 32.9%\n",
      "Feature = Medusa, winning percentage = 35.7%\n",
      "Feature = Phantom Assassin, winning percentage = 37.1%\n",
      "Feature = Morphling, winning percentage = 39.5%\n",
      "Feature = Timbersaw, winning percentage = 39.9%\n",
      "Feature = Enchantress, winning percentage = 40.2%\n",
      "Feature = Alchemist, winning percentage = 40.5%\n",
      "Feature = Invoker, winning percentage = 40.8%\n",
      "Feature = Anti-Mage, winning percentage = 41.8%\n",
      "Feature = Wisp, winning percentage = 53.3%\n",
      "Feature = Vengeful Spirit, winning percentage = 53.6%\n",
      "Feature = Luna, winning percentage = 53.6%\n",
      "Feature = Centaur Warrunner, winning percentage = 54.2%\n",
      "Feature = Spirit Breaker, winning percentage = 54.8%\n",
      "Feature = Phantom Lancer, winning percentage = 55.0%\n",
      "Feature = Zeus, winning percentage = 55.9%\n",
      "Feature = Warlock, winning percentage = 56.6%\n",
      "Feature = Visage, winning percentage = 57.7%\n",
      "Feature = Nyx Assassin, winning percentage = 59.2%\n"
     ]
    }
   ],
   "source": [
    "for i, total, win in features_for_second_team[:10] + features_for_second_team[-10:]:\n",
    "    print ('Feature = %s, winning percentage = %.1f%%' % (vocab.get_word(i), win*100/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that picking Meepo (http://dota.wikia.com/wiki/Meepo_the_Geomancer) or Medusa (http://dota.wikia.com/wiki/Medusa_the_Gorgon) or Broodmother (http://dota.wikia.com/wiki/Black_Arachnia_the_Broodmother) would aversely affect your team performance. On the other side, Nyx Assassin (http://dota.wikia.com/wiki/Nyx_Assassin) or Warlock (http://dota.wikia.com/wiki/Demnok_Lamnik_the_Warlock) or Luna (http://dota.wikia.com/wiki/Luna_Moonfang_the_Moon_Rider) are very good heroes that anyteam should pick for winning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is enforcing our original thought that perhaps we don't need to treat two teams separately. A hero pick (feature) could be a good indicator for outcome of the match without regarding to which team picking that hero. Another interpretation is that there is no strong bias in the selection of the members for each team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 139 is out of bounds for axis 1 with size 97",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-2188dadb2128>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf_for_second\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlen\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwin\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures_for_second_team\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbest_k\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeatures_for_second_team\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbest_k\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_for_first\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mf_for_second\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 139 is out of bounds for axis 1 with size 97"
     ]
    }
   ],
   "source": [
    "best_k = 15\n",
    "f_for_first = [i for i, total, win in features_for_first_team[:best_k] + features_for_first_team[-best_k:]]\n",
    "f_for_second = [i + vocab.len for i, total, win in features_for_second_team[:best_k] + features_for_second_team[-best_k:]]\n",
    "\n",
    "X_r = X[:, f_for_first + f_for_second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 40, 94, 31, 7, 75, 43, 8, 52, 5, 87, 57, 79, 1, 28, 16, 29, 96, 86, 73, 33, 89, 92, 37, 23, 70, 34, 14, 19, 69]\n",
      "[42, 31, 94, 75, 43, 40, 85, 8, 5, 7, 28, 74, 90, 56, 59, 9, 62, 23, 86, 3, 63, 92, 69, 29, 89, 70, 37, 19, 39, 14]\n"
     ]
    }
   ],
   "source": [
    "print (f_for_first)\n",
    "print ([i for i, total, win in features_for_second_team[:best_k] + features_for_second_team[-best_k:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5, 70, 7, 8, 69, 75, 14, 19, 85, 23, 89, 92, 29, 94, 31, 33, 34, 37, 39, 40, 42, 43, 52, 63}\n"
     ]
    }
   ],
   "source": [
    "best_f = set([i for i, total, win in features_for_first_team[:10] + features_for_first_team[-10:]]).union([i for i, total, win in features_for_second_team[:10] + features_for_second_team[-10:]])\n",
    "print (best_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601333333333\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X_r, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LogisticRegression()\n",
    "h = final_model.fit(X_r, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81677673,  0.57499219,  0.45694456,  0.34542858,  0.35697136,\n",
       "         0.25042017,  0.28351395,  0.2347544 ,  0.20150746,  0.18919355,\n",
       "         0.22454607,  0.22966371,  0.229111  ,  0.20464181,  0.18805431,\n",
       "        -0.22979506, -0.20754391, -0.22435342, -0.21644672, -0.26578194,\n",
       "        -0.23921589, -0.3082163 , -0.30379924, -0.30825253, -0.35380314,\n",
       "        -0.30692574, -0.35971862, -0.38457256, -0.41606547, -0.45076123,\n",
       "        -0.73790523, -0.63810305, -0.50621481, -0.49943388, -0.40936881,\n",
       "        -0.30463815, -0.28971389, -0.31520699, -0.28108395, -0.27297841,\n",
       "        -0.23743515, -0.23468561, -0.20902621, -0.24810791, -0.2058793 ,\n",
       "         0.18931256,  0.21837809,  0.19669076,  0.23303521,  0.26475739,\n",
       "         0.24176284,  0.25048168,  0.2001663 ,  0.31128437,  0.25171945,\n",
       "         0.25122132,  0.32045726,  0.37789383,  0.44938722,  0.50260205]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02959285])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_for_first = dict((k, i) for i, k in enumerate([42, 40, 94, 31, 7, 75, 43, 8, 52, 5, 87, 57, 79, 1, 28, 16, 29, 96, 86, 73, 33, 89, 92, 37, 23, 70, 34, 14, 19, 69]))\n",
    "f_for_second = dict((k, i) for i, k in enumerate([42, 31, 94, 75, 43, 40, 85, 8, 5, 7, 28, 74, 90, 56, 59, 9, 62, 23, 86, 3, 63, 92, 69, 29, 89, 70, 37, 19, 39, 14]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Double feature **\n",
    "\n",
    "As the improve in the performance is not significant, we want to extend our analysis to include these types of features: may be if one team picks two complementary heroes, they might create a very strong team, or if there are two heroes from two teams, that one generally dominates another, one team might normally win. We would test that by calculating the following features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "double_same = defaultdict(int)\n",
    "double_same_win = defaultdict(int)\n",
    "double_diff = defaultdict(int)\n",
    "double_diff_win = defaultdict(int)\n",
    "\n",
    "for match in matches:\n",
    "    team_1, team_2, result = match\n",
    "    \n",
    "    for h_1 in team_1:\n",
    "        for h_2 in team_1:\n",
    "            if h_1 < h_2:\n",
    "                double_same[(h_1, h_2)] += 1\n",
    "                if result == 1:\n",
    "                    double_same_win[(h_1, h_2)] += 1\n",
    "                    \n",
    "    for h_1 in team_2:\n",
    "        for h_2 in team_2:\n",
    "            if h_1 < h_2:\n",
    "                double_same[(h_1, h_2)] += 1\n",
    "                if result == 2:\n",
    "                    double_same_win[(h_1, h_2)] += 1\n",
    "    \n",
    "    for h_1 in team_1:\n",
    "        for h_2 in team_2:\n",
    "            if h_1 < h_2:\n",
    "                double_diff[(h_1, h_2)] += 1\n",
    "                if result == 1:\n",
    "                    double_diff_win[(h_1, h_2)] += 1\n",
    "            else:\n",
    "                double_diff[(h_2, h_1)] += 1\n",
    "                if result == 2:\n",
    "                    double_diff_win[(h_2, h_1)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_same_features = sorted([(key, double_same[key], double_same_win[key]) for key in double_same], key = lambda a : a[2] / a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "double_diff_features = sorted([(key, double_diff[key], double_diff_win[key]) for key in double_same], key = lambda a : a[2] / a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When a team picks both Leshrac and Treant Protector, winning percentage = 18.8%\n",
      "When a team picks both Treant Protector and Lycanthrope, winning percentage = 22.2%\n",
      "When a team picks both Treant Protector and Ursa, winning percentage = 22.2%\n",
      "When a team picks both Naga Siren and Beastmaster, winning percentage = 23.8%\n",
      "When a team picks both Shadow Shaman and Crystal Maiden, winning percentage = 24.4%\n",
      "When a team picks both Bane and Disruptor, winning percentage = 25.0%\n",
      "When a team picks both Treant Protector and Chen, winning percentage = 25.0%\n",
      "When a team picks both Spectre and Lycanthrope, winning percentage = 25.0%\n",
      "When a team picks both Sven and Death Prophet, winning percentage = 25.8%\n",
      "When a team picks both Huskar and Skeleton King, winning percentage = 25.9%\n",
      "When a team picks both Weaver and Razor, winning percentage = 26.1%\n",
      "When a team picks both Lone Druid and Doom, winning percentage = 26.8%\n",
      "When a team picks both Leshrac and Huskar, winning percentage = 27.8%\n",
      "When a team picks both Sniper and Shadow Demon, winning percentage = 27.9%\n",
      "When a team picks both Dark Seer and Skeleton King, winning percentage = 28.0%\n",
      "When a team picks both Chaos Knight and Skeleton King, winning percentage = 28.0%\n",
      "When a team picks both Ogre Magi and Witch Doctor, winning percentage = 28.6%\n",
      "When a team picks both Shadow Shaman and Huskar, winning percentage = 28.6%\n",
      "When a team picks both Naga Siren and Bloodseeker, winning percentage = 28.6%\n",
      "When a team picks both Huskar and Chen, winning percentage = 28.6%\n",
      "When a team picks both Slardar and Chen, winning percentage = 28.6%\n",
      "When a team picks both Witch Doctor and Outworld Devourer, winning percentage = 28.6%\n",
      "When a team picks both Slardar and Batrider, winning percentage = 28.9%\n",
      "When a team picks both Puck and Naga Siren, winning percentage = 29.3%\n",
      "When a team picks both Doom and Ancient Apparition, winning percentage = 29.4%\n",
      "When a team picks both Sven and Pugna, winning percentage = 29.4%\n",
      "When a team picks both Bane and Lion, winning percentage = 29.4%\n",
      "When a team picks both Ancient Apparition and Lycanthrope, winning percentage = 29.4%\n",
      "When a team picks both Sven and Lone Druid, winning percentage = 29.4%\n",
      "When a team picks both Huskar and Ancient Apparition, winning percentage = 29.6%\n",
      "When a team picks both Spectre and Batrider, winning percentage = 29.6%\n",
      "When a team picks both Slardar and Beastmaster, winning percentage = 29.6%\n",
      "When a team picks both Slardar and Skeleton King, winning percentage = 30.0%\n",
      "When a team picks both Razor and Clinkz, winning percentage = 30.4%\n",
      "When a team picks both Treant Protector and Huskar, winning percentage = 30.4%\n",
      "When a team picks both Witch Doctor and Death Prophet, winning percentage = 30.4%\n",
      "When a team picks both Shadow Shaman and Chen, winning percentage = 30.4%\n",
      "When a team picks both Templar Assassin and Lycanthrope, winning percentage = 30.8%\n",
      "When a team picks both Shadow Fiend and Templar Assassin, winning percentage = 30.8%\n",
      "When a team picks both Leshrac and Pugna, winning percentage = 30.8%\n",
      "When a team picks both Treant Protector and Dazzle, winning percentage = 30.8%\n",
      "When a team picks both Silencer and Ancient Apparition, winning percentage = 31.0%\n",
      "When a team picks both Slardar and Lina, winning percentage = 31.2%\n",
      "When a team picks both Spectre and Dragon Knight, winning percentage = 31.2%\n",
      "When a team picks both Beastmaster and Lycanthrope, winning percentage = 31.2%\n",
      "When a team picks both Doom and Templar Assassin, winning percentage = 31.4%\n",
      "When a team picks both Razor and Crystal Maiden, winning percentage = 31.4%\n",
      "When a team picks both Doom and Lycanthrope, winning percentage = 31.6%\n",
      "When a team picks both Windrunner and Death Prophet, winning percentage = 31.8%\n",
      "When a team picks both Treant Protector and Templar Assassin, winning percentage = 32.0%\n",
      "When a team picks both Shadow Shaman and Ogre Magi, winning percentage = 66.7%\n",
      "When a team picks both Bane and Chen, winning percentage = 66.7%\n",
      "When a team picks both Riki and Tidehunter, winning percentage = 66.7%\n",
      "When a team picks both Necrolyte and Undying, winning percentage = 66.7%\n",
      "When a team picks both Sand King and Jakiro, winning percentage = 67.1%\n",
      "When a team picks both Shadow Fiend and Lycanthrope, winning percentage = 67.4%\n",
      "When a team picks both Leshrac and Crystal Maiden, winning percentage = 67.5%\n",
      "When a team picks both Jakiro and Night Stalker, winning percentage = 67.6%\n",
      "When a team picks both Lion and Lycanthrope, winning percentage = 67.6%\n",
      "When a team picks both Tinker and Viper, winning percentage = 67.6%\n",
      "When a team picks both Necrolyte and Jakiro, winning percentage = 67.6%\n",
      "When a team picks both Dark Seer and Lycanthrope, winning percentage = 67.6%\n",
      "When a team picks both Clockwerk and Slark, winning percentage = 67.7%\n",
      "When a team picks both Dragon Knight and Death Prophet, winning percentage = 67.9%\n",
      "When a team picks both Chaos Knight and Lycanthrope, winning percentage = 68.0%\n",
      "When a team picks both Spectre and Chaos Knight, winning percentage = 68.0%\n",
      "When a team picks both Sand King and Chaos Knight, winning percentage = 68.1%\n",
      "When a team picks both Ursa and Chaos Knight, winning percentage = 68.4%\n",
      "When a team picks both Chen and Dragon Knight, winning percentage = 68.4%\n",
      "When a team picks both Spectre and Brewmaster, winning percentage = 68.4%\n",
      "When a team picks both Ursa and Skeleton King, winning percentage = 68.6%\n",
      "When a team picks both Beastmaster and Witch Doctor, winning percentage = 68.8%\n",
      "When a team picks both Viper and Night Stalker, winning percentage = 68.8%\n",
      "When a team picks both Crystal Maiden and Jakiro, winning percentage = 68.8%\n",
      "When a team picks both Razor and Lion, winning percentage = 68.8%\n",
      "When a team picks both Clockwerk and Lich, winning percentage = 68.9%\n",
      "When a team picks both Earthshaker and Lich, winning percentage = 69.0%\n",
      "When a team picks both Death Prophet and Lycanthrope, winning percentage = 69.0%\n",
      "When a team picks both Leshrac and Viper, winning percentage = 69.2%\n",
      "When a team picks both Tinker and Skeleton King, winning percentage = 69.2%\n",
      "When a team picks both Batrider and Death Prophet, winning percentage = 69.2%\n",
      "When a team picks both Dazzle and Lycanthrope, winning percentage = 69.6%\n",
      "When a team picks both Tidehunter and Lich, winning percentage = 70.7%\n",
      "When a team picks both Omniknight and Lich, winning percentage = 70.8%\n",
      "When a team picks both Clockwerk and Ursa, winning percentage = 71.8%\n",
      "When a team picks both Shadow Shaman and Bane, winning percentage = 72.0%\n",
      "When a team picks both Riki and Viper, winning percentage = 72.2%\n",
      "When a team picks both Tinker and Ancient Apparition, winning percentage = 72.2%\n",
      "When a team picks both Spectre and Treant Protector, winning percentage = 72.7%\n",
      "When a team picks both Tinker and Night Stalker, winning percentage = 73.1%\n",
      "When a team picks both Ogre Magi and Dazzle, winning percentage = 74.1%\n",
      "When a team picks both Slardar and Ursa, winning percentage = 74.1%\n",
      "When a team picks both Spectre and Omniknight, winning percentage = 75.0%\n",
      "When a team picks both Venomancer and Treant Protector, winning percentage = 75.0%\n",
      "When a team picks both Leshrac and Omniknight, winning percentage = 75.0%\n",
      "When a team picks both Slardar and Night Stalker, winning percentage = 76.2%\n",
      "When a team picks both Chen and Chaos Knight, winning percentage = 76.9%\n",
      "When a team picks both Ogre Magi and Undying, winning percentage = 78.3%\n",
      "When a team picks both Omniknight and Lycanthrope, winning percentage = 78.6%\n",
      "When a team picks both Omniknight and Night Stalker, winning percentage = 82.1%\n"
     ]
    }
   ],
   "source": [
    "for (first, second), total, win in double_same_features[:select_k] + double_same_features[-select_k:]:\n",
    "    print ('When a team picks both %s and %s, winning percentage = %.1f%%' % (vocab.get_word(first), vocab.get_word(second), win*100/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When a team picks Huskar and the other team picks Ursa, winning percentage of first team = 24.2%\n",
      "When a team picks Naga Siren and the other team picks Chen, winning percentage of first team = 25.0%\n",
      "When a team picks Treant Protector and the other team picks Ursa, winning percentage of first team = 25.0%\n",
      "When a team picks Leshrac and the other team picks Night Stalker, winning percentage of first team = 26.3%\n",
      "When a team picks Leshrac and the other team picks Lich, winning percentage of first team = 26.3%\n",
      "When a team picks Doom and the other team picks Huskar, winning percentage of first team = 26.7%\n",
      "When a team picks Chen and the other team picks Ursa, winning percentage of first team = 26.9%\n",
      "When a team picks Earthshaker and the other team picks Lycanthrope, winning percentage of first team = 27.6%\n",
      "When a team picks Treant Protector and the other team picks Lycanthrope, winning percentage of first team = 27.8%\n",
      "When a team picks Chen and the other team picks Lich, winning percentage of first team = 28.0%\n",
      "When a team picks Spectre and the other team picks Tidehunter, winning percentage of first team = 28.2%\n",
      "When a team picks Lone Druid and the other team picks Night Stalker, winning percentage of first team = 28.3%\n",
      "When a team picks Lone Druid and the other team picks Venomancer, winning percentage of first team = 28.4%\n",
      "When a team picks Razor and the other team picks Ursa, winning percentage of first team = 28.6%\n",
      "When a team picks Lina and the other team picks Ursa, winning percentage of first team = 28.8%\n",
      "When a team picks Razor and the other team picks Omniknight, winning percentage of first team = 29.2%\n",
      "When a team picks Treant Protector and the other team picks Witch Doctor, winning percentage of first team = 29.2%\n",
      "When a team picks Slardar and the other team picks Viper, winning percentage of first team = 29.3%\n",
      "When a team picks Gyrocopter and the other team picks Spectre, winning percentage of first team = 29.8%\n",
      "When a team picks Bane and the other team picks Lich, winning percentage of first team = 30.0%\n",
      "When a team picks Death Prophet and the other team picks Night Stalker, winning percentage of first team = 30.0%\n",
      "When a team picks Clinkz and the other team picks Viper, winning percentage of first team = 30.2%\n",
      "When a team picks Crystal Maiden and the other team picks Lich, winning percentage of first team = 30.3%\n",
      "When a team picks Bane and the other team picks Lycanthrope, winning percentage of first team = 30.4%\n",
      "When a team picks Puck and the other team picks Ursa, winning percentage of first team = 30.4%\n",
      "When a team picks Shadow Shaman and the other team picks Jakiro, winning percentage of first team = 30.6%\n",
      "When a team picks Leshrac and the other team picks Ogre Magi, winning percentage of first team = 30.8%\n",
      "When a team picks Viper and the other team picks Pugna, winning percentage of first team = 30.8%\n",
      "When a team picks Slardar and the other team picks Naga Siren, winning percentage of first team = 30.8%\n",
      "When a team picks Bloodseeker and the other team picks Lycanthrope, winning percentage of first team = 31.0%\n",
      "When a team picks Treant Protector and the other team picks Outworld Devourer, winning percentage of first team = 31.2%\n",
      "When a team picks Clockwerk and the other team picks Spectre, winning percentage of first team = 31.2%\n",
      "When a team picks Dazzle and the other team picks Jakiro, winning percentage of first team = 31.4%\n",
      "When a team picks Treant Protector and the other team picks Dazzle, winning percentage of first team = 31.6%\n",
      "When a team picks Pugna and the other team picks Lycanthrope, winning percentage of first team = 31.8%\n",
      "When a team picks Treant Protector and the other team picks Batrider, winning percentage of first team = 31.8%\n",
      "When a team picks Razor and the other team picks Beastmaster, winning percentage of first team = 32.0%\n",
      "When a team picks Doom and the other team picks Pugna, winning percentage of first team = 32.1%\n",
      "When a team picks Dazzle and the other team picks Ancient Apparition, winning percentage of first team = 32.4%\n",
      "When a team picks Leshrac and the other team picks Ancient Apparition, winning percentage of first team = 32.5%\n",
      "When a team picks Slardar and the other team picks Batrider, winning percentage of first team = 32.8%\n",
      "When a team picks Shadow Shaman and the other team picks Razor, winning percentage of first team = 33.3%\n",
      "When a team picks Lone Druid and the other team picks Ursa, winning percentage of first team = 33.3%\n",
      "When a team picks Clinkz and the other team picks Night Stalker, winning percentage of first team = 33.3%\n",
      "When a team picks Razor and the other team picks Lycanthrope, winning percentage of first team = 33.3%\n",
      "When a team picks Naga Siren and the other team picks Beastmaster, winning percentage of first team = 33.3%\n",
      "When a team picks Silencer and the other team picks Chen, winning percentage of first team = 33.3%\n",
      "When a team picks Sven and the other team picks Spectre, winning percentage of first team = 33.3%\n",
      "When a team picks Doom and the other team picks Skeleton King, winning percentage of first team = 33.3%\n",
      "When a team picks Clockwerk and the other team picks Batrider, winning percentage of first team = 33.8%\n",
      "When a team picks Tidehunter and the other team picks Sniper, winning percentage of first team = 65.6%\n",
      "When a team picks Omniknight and the other team picks Brewmaster, winning percentage of first team = 65.6%\n",
      "When a team picks Tidehunter and the other team picks Ogre Magi, winning percentage of first team = 65.7%\n",
      "When a team picks Ursa and the other team picks Beastmaster, winning percentage of first team = 65.7%\n",
      "When a team picks Venomancer and the other team picks Lycanthrope, winning percentage of first team = 65.7%\n",
      "When a team picks Omniknight and the other team picks Huskar, winning percentage of first team = 65.7%\n",
      "When a team picks Mirana and the other team picks Naga Siren, winning percentage of first team = 65.9%\n",
      "When a team picks Jakiro and the other team picks Dragon Knight, winning percentage of first team = 65.9%\n",
      "When a team picks Lion and the other team picks Death Prophet, winning percentage of first team = 66.0%\n",
      "When a team picks Sand King and the other team picks Weaver, winning percentage of first team = 66.3%\n",
      "When a team picks Puck and the other team picks Naga Siren, winning percentage of first team = 66.7%\n",
      "When a team picks Leshrac and the other team picks Slardar, winning percentage of first team = 66.7%\n",
      "When a team picks Clockwerk and the other team picks Sniper, winning percentage of first team = 66.7%\n",
      "When a team picks Chen and the other team picks Skeleton King, winning percentage of first team = 66.7%\n",
      "When a team picks Lich and the other team picks Bloodseeker, winning percentage of first team = 66.7%\n",
      "When a team picks Crystal Maiden and the other team picks Undying, winning percentage of first team = 66.7%\n",
      "When a team picks Shadow Shaman and the other team picks Templar Assassin, winning percentage of first team = 67.4%\n",
      "When a team picks Crystal Maiden and the other team picks Clinkz, winning percentage of first team = 67.5%\n",
      "When a team picks Slardar and the other team picks Huskar, winning percentage of first team = 67.7%\n",
      "When a team picks Clockwerk and the other team picks Death Prophet, winning percentage of first team = 67.7%\n",
      "When a team picks Ogre Magi and the other team picks Pugna, winning percentage of first team = 67.9%\n",
      "When a team picks Sand King and the other team picks Ursa, winning percentage of first team = 67.9%\n",
      "When a team picks Spectre and the other team picks Kunkka, winning percentage of first team = 68.0%\n",
      "When a team picks Treant Protector and the other team picks Razor, winning percentage of first team = 68.4%\n",
      "When a team picks Dark Seer and the other team picks Naga Siren, winning percentage of first team = 68.5%\n",
      "When a team picks Enigma and the other team picks Huskar, winning percentage of first team = 68.6%\n",
      "When a team picks Razor and the other team picks Naga Siren, winning percentage of first team = 68.8%\n",
      "When a team picks Razor and the other team picks Chen, winning percentage of first team = 68.8%\n",
      "When a team picks Slark and the other team picks Naga Siren, winning percentage of first team = 68.8%\n",
      "When a team picks Clockwerk and the other team picks Crystal Maiden, winning percentage of first team = 68.8%\n",
      "When a team picks Slark and the other team picks Chen, winning percentage of first team = 69.0%\n",
      "When a team picks Necrolyte and the other team picks Sniper, winning percentage of first team = 69.2%\n",
      "When a team picks Razor and the other team picks Death Prophet, winning percentage of first team = 69.2%\n",
      "When a team picks Weaver and the other team picks Chen, winning percentage of first team = 69.2%\n",
      "When a team picks Lich and the other team picks Night Stalker, winning percentage of first team = 69.2%\n",
      "When a team picks Bane and the other team picks Dazzle, winning percentage of first team = 69.4%\n",
      "When a team picks Tinker and the other team picks Death Prophet, winning percentage of first team = 69.4%\n",
      "When a team picks Faceless Void and the other team picks Naga Siren, winning percentage of first team = 69.7%\n",
      "When a team picks Omniknight and the other team picks Templar Assassin, winning percentage of first team = 70.0%\n",
      "When a team picks Slardar and the other team picks Sniper, winning percentage of first team = 71.1%\n",
      "When a team picks Dark Seer and the other team picks Beastmaster, winning percentage of first team = 71.4%\n",
      "When a team picks Slark and the other team picks Razor, winning percentage of first team = 71.7%\n",
      "When a team picks Sven and the other team picks Witch Doctor, winning percentage of first team = 72.0%\n",
      "When a team picks Razor and the other team picks Skeleton King, winning percentage of first team = 72.2%\n",
      "When a team picks Spectre and the other team picks Beastmaster, winning percentage of first team = 73.9%\n",
      "When a team picks Omniknight and the other team picks Beastmaster, winning percentage of first team = 75.0%\n",
      "When a team picks Spectre and the other team picks Death Prophet, winning percentage of first team = 76.5%\n",
      "When a team picks Ogre Magi and the other team picks Bloodseeker, winning percentage of first team = 77.4%\n",
      "When a team picks Silencer and the other team picks Naga Siren, winning percentage of first team = 77.8%\n",
      "When a team picks Naga Siren and the other team picks Death Prophet, winning percentage of first team = 81.0%\n"
     ]
    }
   ],
   "source": [
    "for (first, second), total, win in double_diff_features[:select_k] + double_diff_features[-select_k:]:\n",
    "    print ('When a team picks %s and the other team picks %s, winning percentage of first team = %.1f%%' % (vocab.get_word(first), vocab.get_word(second), win*100/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "double_vocab = Vocabulary()\n",
    "select_k = 50\n",
    "for (first, second), _, _ in double_same_features[:select_k] + double_same_features[-select_k:]:\n",
    "    double_vocab.add ( (first, second) )\n",
    "\n",
    "for (first, second), _, _ in double_diff_features[:select_k] + double_diff_features[-select_k:]:\n",
    "    double_vocab.add ( (first, second) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_vocab.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_r_2 = np.zeros((len(X), 2 * double_vocab.len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, match in enumerate(matches):\n",
    "    team_1, team_2, result = match\n",
    "    \n",
    "    for h_1 in team_1:\n",
    "        for h_2 in team_1:\n",
    "            if double_vocab.isIn((h_1, h_2)):\n",
    "                t = double_vocab.get_index((h_1, h_2))\n",
    "                X_r_2[i, t] = 1\n",
    "                    \n",
    "    for h_1 in team_2:\n",
    "        for h_2 in team_2:\n",
    "            if double_vocab.isIn((h_1, h_2)):\n",
    "                t = double_vocab.get_index((h_1, h_2))\n",
    "                X_r_2[i, t + double_vocab.len] = 1\n",
    "    \n",
    "    for h_1 in team_1:\n",
    "        for h_2 in team_2:\n",
    "            if double_vocab.isIn((h_1, h_2)):\n",
    "                t = double_vocab.get_index((h_1, h_2))\n",
    "                X_r_2[i, t] = 1\n",
    "            elif double_vocab.isIn((h_2, h_1)):\n",
    "                t = double_vocab.get_index((h_2, h_1))\n",
    "                X_r_2[i, t + double_vocab.len] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 80],\n",
       "       [326]], dtype=int64)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere( X_r_2[24] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_r_3 = np.concatenate([X_r, X_r_2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.547266666667\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X_r_3, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582733333333\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "results = cross_val_score(model, X_r_3, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 194)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it comes to the point that without some new insight into the data set, we would not be able to move forward.\n",
    "\n",
    "One of the thing that we could ask is: is there any structure in the data, for example, is there any order in the data?\n",
    "\n",
    "Let's draw the winning percentage for a few heroes across the players on both sides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_feature_total = defaultdict(lambda: defaultdict(int))\n",
    "pos_feature_win = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    team_1, team_2, result = match\n",
    "    \n",
    "    for j, f in enumerate(team_1):\n",
    "        pos_feature_total[j][f] += 1\n",
    "        if result == 1:\n",
    "            pos_feature_win[j][f] += 1\n",
    "    \n",
    "    for j, f in enumerate(team_2):\n",
    "        pos_feature_total[j+5][f] += 1\n",
    "        if result == 2:\n",
    "            pos_feature_win[j+5][f] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_feature_winning = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for k1 in pos_feature_win:\n",
    "    for k2 in pos_feature_win[k1]:\n",
    "        pos_feature_winning[k1][k2] = float(pos_feature_win[k1][k2])/pos_feature_total[k1][k2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eedeeb27b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the first side\n",
    "# 20 heroes\n",
    "\n",
    "ind = np.arange(20)\n",
    "\n",
    "bottom = np.zeros(20)\n",
    "\n",
    "for i in range(5):\n",
    "    height = np.array([pos_feature_winning[0][pos] for pos in range(20)])\n",
    "    plt.bar(ind, height, bottom = bottom)\n",
    "    bottom += height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 408,  375,  388,  399,  273,  910,  527,  395,  359,  469,  286,\n",
       "        348,  400,  329,  954,  257,  555,  222,  304,  362,  603, 1213,\n",
       "        505,  676,  899,  513,  733,  428,  346,  340,  147,  146,  403,\n",
       "        506,  636,  188,  549,  377,  244,  167,  206,  424,  100,  229,\n",
       "        293,  405,  415,  504,  251,  286,  347,  506,  367,  351,  757,\n",
       "        379,  345,  215,  280,  177,  913,  179,  241,  342,  483,  423,\n",
       "        346,  244,  954,  524,  688,  294,  464,  437,  314,  289,  697,\n",
       "        267,  271,  308,  286,  249,  751,  312,  202,  208,  293,  223,\n",
       "        253,  317,  588,  201,  445,  170,  246,  483,  279])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_and((X == 1), (np.repeat(Y[:,np.newaxis], vocab.len, 1) == 0)).sum(axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 362,  333,  359,  363,  245,  735,  472,  379,  277,  447,  248,\n",
       "        337,  415,  301,  939,  222,  478,  198,  298,  347,  524, 1050,\n",
       "        558,  611,  787,  441,  729,  398,  308,  329,  124,   93,  386,\n",
       "        408,  506,  159,  449,  341,  234,  153,  210,  371,  107,  201,\n",
       "        229,  421,  440,  463,  232,  300,  295,  444,  398,  383,  739,\n",
       "        366,  326,  226,  243,  169,  813,  166,  252,  355,  435,  403,\n",
       "        308,  249,  876,  490,  634,  278,  407,  394,  281,  232,  591,\n",
       "        286,  244,  300,  244,  233,  684,  284,  177,  186,  289,  226,\n",
       "        226,  301,  508,  195,  362,  182,  148,  464,  231])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_and((X == -1), (np.repeat(Y[:,np.newaxis], vocab.len, 1) == 1)).sum(axis = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class ModifiedNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        # for each feature, store a value corresponding to \n",
    "        self.f_scores = None\n",
    "    \n",
    "    def fit(self, X, Y, sample_weight = None):\n",
    "        # We know that when a feature == 1, it belongs to first team\n",
    "        # When the feature == -1, it belongs to the second team\n",
    "        self.f_total = (X != 0).sum(axis = 0)\n",
    "        \n",
    "        Y_repeat = np.repeat(Y[:,np.newaxis], vocab.len, 1)\n",
    "        \n",
    "        self.f_win = np.logical_and(X == 1, Y_repeat == 0).sum(axis = 0 ) + np.logical_and(X == -1, Y_repeat == 1).sum(axis = 0 )\n",
    "        \n",
    "        self.f_scores = self.f_win / self.f_total\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Here we will modify prediction according to our preference\n",
    "        t  = np.repeat(self.f_scores[np.newaxis, :], len(X), 0)\n",
    "        q = np.sum( t * X, axis = 1 )\n",
    "        q = q < 0\n",
    "        return np.sum(q[:, np.newaxis], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_total = defaultdict(int)\n",
    "feature_win = defaultdict(int)\n",
    "for i, match in enumerate(matches):\n",
    "    win_team, loss_team, result = match\n",
    "    \n",
    "    if result == 2:\n",
    "        win_team, loss_team = loss_team, win_team\n",
    "\n",
    "    for v in win_team:\n",
    "        feature_total[v] += 1\n",
    "        feature_win[v] += 1\n",
    "    for v in loss_team:\n",
    "        feature_total[v] += 1\n",
    "\n",
    "f_score = dict([(k, float(feature_win[k])/feature_total[k] ) for k in feature_total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597333333333\n"
     ]
    }
   ],
   "source": [
    "model = ModifiedNaiveBayes()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dimensions for head-to-head performance of the best heroes of both sides\n",
    "X_numeric = np.zeros((X.shape[0], 13))\n",
    "X_numeric_revert = np.zeros((X.shape[0], 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(X):\n",
    "    team_1 = np.argwhere(x == 1).flatten()\n",
    "    team_2 = np.argwhere(x == -1).flatten()\n",
    "\n",
    "    team_1 = sorted(team_1, key = lambda t : model.f_scores[t])\n",
    "    team_2 = sorted(team_2, key = lambda t : model.f_scores[t])\n",
    "    \n",
    "    X_numeric[i][:5] = model.f_scores[team_1]\n",
    "    X_numeric[i][5:10] = model.f_scores[team_2]\n",
    "    \n",
    "    X_numeric_revert[i][:5] = model.f_scores[team_2]\n",
    "    X_numeric_revert[i][5:10] = model.f_scores[team_1]\n",
    "    \n",
    "    # Performance of two best heroes on two sides when they play along each other\n",
    "    t1 = tuple(sorted(team_1[3:]))\n",
    "    t2 = tuple(sorted(team_2[3:]))\n",
    "    \n",
    "    X_numeric[i][10] = double_same_win[t1] / double_same[t1]\n",
    "    X_numeric[i][11] = double_same_win[t2] / double_same[t2]\n",
    "    X_numeric_revert[i][10] = double_same_win[t2] / double_same[t2]\n",
    "    X_numeric_revert[i][11] = double_same_win[t1] / double_same[t1]\n",
    "    \n",
    "    if team_1[4] < team_2[4]:\n",
    "        t3 = (team_1[4], team_2[4])\n",
    "    \n",
    "        X_numeric[i][12] = double_diff_win[t3] / double_diff[t3]\n",
    "        X_numeric_revert[i][12] = 1 - double_diff_win[t3] / double_diff[t3]\n",
    "    else:\n",
    "        t3 = (team_2[4], team_1[4])\n",
    "        X_numeric[i][12] = 1 - double_diff_win[t3] / double_diff[t3]\n",
    "        X_numeric_revert[i][12] = double_diff_win[t3] / double_diff[t3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 13)\n"
     ]
    }
   ],
   "source": [
    "print (X_numeric.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6158\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression()\n",
    "results = cross_val_score(m, X_numeric[:, 10:], Y , cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_numeric[:, 10:], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61619999999999997"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X_numeric[:, 10:], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.49010919])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.29557372,  4.10156613, -2.93904037]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608933333333\n"
     ]
    }
   ],
   "source": [
    "m_2 = LogisticRegression()\n",
    "results = cross_val_score(m_2, X_numeric[:,:10], Y , cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_2.fit(X_numeric[:,:10], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24702304])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.39906672, -3.53819079, -3.98052895, -3.75992271, -3.50958269,\n",
       "         4.55141358,  2.86816211,  3.18571958,  3.73144632,  3.26923679]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_3 = LogisticRegression()\n",
    "m_3.fit(X_numeric[:,list(range(10)) + [12]], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18885693])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_3.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.39687045, -3.54214475, -3.98701025, -3.76362845, -3.55188428,\n",
       "         4.55107576,  2.86291   ,  3.18446881,  3.7271194 ,  3.22678909,\n",
       "         0.22959604]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric_revert = np.concatenate( [X_numeric[:, 5:10], X_numeric[:, :5]], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 13)\n"
     ]
    }
   ],
   "source": [
    "X_sym = np.concatenate( [X_numeric, X_numeric_revert] )\n",
    "print (X_sym.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_revert = 1 - Y\n",
    "Y_sym = np.concatenate([Y, Y_revert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634666666667\n"
     ]
    }
   ],
   "source": [
    "m_4 = LogisticRegression()\n",
    "results = cross_val_score(m_4, X_sym, Y_sym , cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_4.fit(X_sym[:,:10], Y_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.14632161, -3.44830095, -4.18099486, -4.0386094 , -3.50826214,\n",
       "         4.14632162,  3.44830095,  4.18099486,  4.0386094 ,  3.50826215]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.64119811e-09])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_4.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
