{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The records provided to you are the grades obtained by students who had opted for the following combinations of subjects or courses and obtained a passing grade in each subject. The individual subjects in the data are: \n",
    "English, Physics, Chemistry, Mathematics, Computer Science, Biology, Physical Education, Economics, Accountancy and Business Studies.\n",
    "\n",
    "The most dominant subject combinations, account for approximately 99% of the data are:\n",
    "\n",
    "`\n",
    "English, Physics, Chemistry, Mathematics, Computer Science    \n",
    "English, Physics, Chemistry, Mathematics, Physical Education    \n",
    "English, Physics, Chemistry, Mathematics, Economics    \n",
    "English, Physics, Chemistry, Mathematics, Biology  \n",
    "English, Economics, Accountancy, Mathematics, Business Studies  \n",
    "`\n",
    "\n",
    "The grades of students in four subjects (other than Mathematics) are provided to you. Can you predict what grade they had obtained in Mathematics?\n",
    "\n",
    "To help you build a prediction engine, we will provide you with a training file, containing the grade points obtained by students with the above subject combinations, in all five subjects.\n",
    "\n",
    "** Scoring **\n",
    "\n",
    "For each of the N records in the input file, we will compute:\n",
    "\n",
    "`p = abs(Predicted Grade Point in Mathematics - Actual Grade Point in Mathematics)`\n",
    "\n",
    "Where 'abs' indicates the Absolute Value or Magnitude. If p = 0 or 1 your answer for that particular student record will be considered correct. i.e, we allow a tolerance of one grade point away from the correct answer, to take into consideration the marginal errors which might occur during the testing or grading process.\n",
    "\n",
    "`Score = 100 * ((C-W)/N) `\n",
    "\n",
    "Where C = Number of Correct predictions, not more than one grade point away from the actual grade point assigned. \n",
    "\n",
    "W = Number of wrong (incorrect) predictions and \n",
    "\n",
    "N = Total number of records in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chemistry': 7,\n",
       " 'English': 4,\n",
       " 'Mathematics': 6,\n",
       " 'PhysicalEducation': 3,\n",
       " 'Physics': 8,\n",
       " 'serial': 195490}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"\"\"{\"Physics\":8,\"Chemistry\":7,\"PhysicalEducation\":3,\"English\":4,\"Mathematics\":6,\"serial\":195490}\"\"\"\n",
    "json.loads(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a separate model for each combination of subject. Because we know that 99% of test just belongs to 5 combinations, we can focus on these four combinations only. For all the other case, we can just produce an average score of that person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combinations_text = ['English, Physics, Chemistry, ComputerScience, Mathematics',\n",
    "'English, Physics, Chemistry, PhysicalEducation, Mathematics',\n",
    "'English, Physics, Chemistry, Economics, Mathematics',\n",
    "'English, Physics, Chemistry, Biology, Mathematics',  \n",
    "'English, Economics, Accountancy, BusinessStudies, Mathematics']\n",
    "combinations = [c.split(', ') for c in combinations_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['English', 'Physics', 'Chemistry', 'ComputerScience', 'Mathematics'],\n",
       " ['English', 'Physics', 'Chemistry', 'PhysicalEducation', 'Mathematics'],\n",
       " ['English', 'Physics', 'Chemistry', 'Economics', 'Mathematics'],\n",
       " ['English', 'Physics', 'Chemistry', 'Biology', 'Mathematics'],\n",
       " ['English', 'Economics', 'Accountancy', 'BusinessStudies', 'Mathematics']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_data_has_combination(data, combination):\n",
    "    for subject in combination:\n",
    "        if subject not in data:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def check_data_has_combination_test(data, combination):\n",
    "    for subject in combination:\n",
    "        if subject != 'Mathematics' and subject not in data:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_data_from_combination(data, combination):\n",
    "    d = []\n",
    "    for subject in combination:\n",
    "        if subject in data:\n",
    "            d.append(data[subject])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = []\n",
    "# 5 trees for 5 combinations \n",
    "for i in range(5):\n",
    "#     regressors.append(DecisionTreeRegressor(criterion = 'mae', max_depth = 10))\n",
    "    regressors.append(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = 'training.json'\n",
    "TEST_INPUT = 'sample-test.in.json'\n",
    "TEST_OUTPUT = 'sample-test.out.json'\n",
    "\n",
    "# Training data\n",
    "X_s = [[] for _ in range(5)]\n",
    "Y_s = [[] for _ in range(5)]\n",
    "\n",
    "\n",
    "# Load training data\n",
    "with open(TRAINING, 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    \n",
    "    for line in lines[1:]:\n",
    "        d = json.loads(line)\n",
    "        \n",
    "        for i, combination in enumerate(combinations):\n",
    "            if check_data_has_combination(d, combination):\n",
    "                sample = get_data_from_combination(d, combination)\n",
    "                X_s[i].append(sample[:4])\n",
    "                Y_s[i].append(sample[4])\n",
    "                break\n",
    "\n",
    "X_s = [np.array(X_s[i]) for i in range(5)]\n",
    "Y_s = [np.array(Y_s[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 5 regressor\n",
    "import numpy as np\n",
    "for i in range(5):\n",
    "    regressors[i].fit( X_s[i],  Y_s[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong answers for combination English, Physics, Chemistry, ComputerScience, Mathematics\n",
      "Score of the first four subjects = [3 5 6 5], predict Math score = 5, correct = 7\n",
      "Score of the first four subjects = [1 4 4 3], predict Math score = 3, correct = 7\n",
      "Score of the first four subjects = [2 5 4 4], predict Math score = 4, correct = 2\n",
      "Score of the first four subjects = [5 5 5 7], predict Math score = 5, correct = 3\n",
      "Score of the first four subjects = [1 4 2 3], predict Math score = 3, correct = 1\n",
      "Score of the first four subjects = [2 5 7 6], predict Math score = 5, correct = 7\n",
      "Score of the first four subjects = [2 2 2 4], predict Math score = 2, correct = 4\n",
      "Score of the first four subjects = [4 5 7 6], predict Math score = 6, correct = 3\n",
      "Wrong answers for combination English, Physics, Chemistry, PhysicalEducation, Mathematics\n",
      "Score of the first four subjects = [3 1 1 1], predict Math score = 1, correct = 3\n",
      "Score of the first four subjects = [5 3 4 5], predict Math score = 3, correct = 8\n",
      "Score of the first four subjects = [3 4 4 1], predict Math score = 4, correct = 6\n",
      "Score of the first four subjects = [3 7 4 4], predict Math score = 5, correct = 8\n",
      "Score of the first four subjects = [5 4 6 3], predict Math score = 5, correct = 2\n",
      "Score of the first four subjects = [4 3 3 5], predict Math score = 3, correct = 5\n",
      "Wrong answers for combination English, Physics, Chemistry, Economics, Mathematics\n",
      "Score of the first four subjects = [3 5 8 2], predict Math score = 4, correct = 1\n",
      "Wrong answers for combination English, Physics, Chemistry, Biology, Mathematics\n",
      "Score of the first four subjects = [4 2 1 2], predict Math score = 2, correct = 8\n",
      "Score of the first four subjects = [3 5 6 7], predict Math score = 6, correct = 8\n",
      "Score of the first four subjects = [3 5 6 4], predict Math score = 5, correct = 8\n",
      "Score of the first four subjects = [1 1 1 1], predict Math score = 1, correct = 3\n",
      "Score of the first four subjects = [2 2 4 2], predict Math score = 3, correct = 1\n",
      "Score of the first four subjects = [5 2 2 4], predict Math score = 2, correct = 4\n",
      "Score of the first four subjects = [1 3 4 1], predict Math score = 3, correct = 6\n",
      "Score of the first four subjects = [2 4 4 4], predict Math score = 4, correct = 6\n",
      "Wrong answers for combination English, Economics, Accountancy, BusinessStudies, Mathematics\n",
      "Score of the first four subjects = [6 3 2 5], predict Math score = 5, correct = 7\n",
      "Score of the first four subjects = [3 2 1 1], predict Math score = 3, correct = 1\n",
      "Score of the first four subjects = [4 6 4 3], predict Math score = 6, correct = 8\n",
      "Score of the first four subjects = [5 3 2 4], predict Math score = 4, correct = 6\n",
      "Score of the first four subjects = [1 1 1 3], predict Math score = 2, correct = 4\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "for i in range(5):\n",
    "    print ('Wrong answers for combination ' + combinations_text[i])\n",
    "    results = regressors[i].score(X_s[i][:], Y_s[i])\n",
    "    predicted = [int(t) for t in regressors[i].predict(X_s[i][:k])]\n",
    "    correct = [t for t in Y_s[i][:k]]\n",
    "    \n",
    "    for j in range(k):\n",
    "        if abs(correct[j] - predicted[j]) > 1:\n",
    "            print ('Score of the first four subjects = %s, predict Math score = %d, correct = %d' % (str(X_s[i][j]), predicted[j], correct[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for this case: \n",
    "\n",
    "`\n",
    "Input = [3 1 1 1]\n",
    "Predict = 1\n",
    "Correct = 3 \n",
    "`\n",
    "\n",
    "We should never predict a score to be at the two extremes, because we would always achieve better result, by predicting one score away from them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down this linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07117858  0.35324092  0.33661138  0.22137701]\n",
      "[ 0.06556114  0.42409517  0.40598503  0.04620729]\n",
      "[ 0.14184456  0.32692396  0.23998285  0.29455252]\n",
      "[-0.09311078  0.31139386  0.46135802  0.12705874]\n",
      "[ 0.15533857  0.3530527   0.52918029  0.16509402]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (regressors[i].coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that most of the time, English score doesn't contribute much to one's Math score. In one of the combinations (English, Physics, Chemistry, Biology, Mathematics), it even has a ***negative*** contribution to Math score. This result is quite logical to me, because as a high school student, I did pretty well in all natural science subjects, but having no time to study English, I didn't get very high score in this subject.\n",
    "\n",
    "Physics, Chemistry and Accountancy are three subjects that correlate well with Math's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "with open(TEST_INPUT, 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    for line in lines[1:]:\n",
    "        d = json.loads(line)\n",
    "        \n",
    "        test_data.append(d)\n",
    "        \n",
    "test_labels = []\n",
    "with open(TEST_OUTPUT, 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        d = int(line.strip())\n",
    "\n",
    "        test_labels.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(r, test_data, test_labels):\n",
    "    predicted = []\n",
    "    origin_predicted = []\n",
    "    \n",
    "    for d in test_data:\n",
    "        for i, combination in enumerate(combinations):\n",
    "            if check_data_has_combination_test(d, combination):\n",
    "                sample_X = get_data_from_combination(d, combination)\n",
    "                y = int(r[i].predict([sample_X])[0])\n",
    "                origin_predicted.append(y)\n",
    "                if y == 1:\n",
    "                    y = 2\n",
    "                if y >= 8 :\n",
    "                    y = 7\n",
    "                predicted.append(y)\n",
    "                break\n",
    "        else:\n",
    "            # Just average it\n",
    "            sum = 0\n",
    "            for subject in d:\n",
    "                if subject != 'serial':\n",
    "                    sum += d[subject]\n",
    "            predicted.append(sum // 4)\n",
    "    \n",
    "    C = 0\n",
    "    W = 0\n",
    "    for predicted_y, y in zip(predicted, test_labels):\n",
    "        if abs(y - predicted_y) <= 1:\n",
    "            C += 1\n",
    "        else:\n",
    "            W += 1\n",
    "    print ( (C - W) * 100 / (C + W) )\n",
    "    \n",
    "    return origin_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.52524090320725\n"
     ]
    }
   ],
   "source": [
    "origin_predicted = evaluate(regressors, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** On Hackkerank **\n",
    "\n",
    "Linear regression approach receive a score of 37.68\n",
    "(32 is passing score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I recognize that we didn't use the following piece of information:\n",
    "\n",
    "`\n",
    "The student is first assessed on a scale of 100. (S)He needs a score of at least 33% to pass in the subject. Among those who pass:\n",
    "\n",
    "Grade 1 is assigned to the top one-eighth of students who pass the course.  \n",
    "Grade 2 is assigned to the next one-eighth of students who pass the course.  \n",
    ".....\n",
    "Grade 8 is assigned to the last one-eighth of students who pass the course.  \n",
    "If more than 1 student share the same score and lie in the margin, they share the higher grade.\n",
    "`\n",
    "\n",
    "Is there any a good way to incorporate this information into our estimation?\n",
    "\n",
    "Firstly, let's draw a histogram of our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8219.,  13350.,  12339.,  11298.,   9755.,   8622.,   4663.,\n",
       "           409.,    152.]),\n",
       " array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSR3DQZLUMRwkSR3DQZLUMRwkSZ3/C+AxZ5zJU7EiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22382c52550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(origin_predicted,  9 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictor is quite biased, giving nearly 14000 people rank 2, and only 4600 people get rank 7, and 400 get rank 8, some even get rank 9, which is an invalid rank. What if instead of using directly the predicted score for finally score, we rerank these predicted score, and produce scores evenly into bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_2(r, test_data, test_labels):\n",
    "    origin_predicted = []\n",
    "    \n",
    "    for test_index, d in enumerate(test_data):\n",
    "        for i, combination in enumerate(combinations):\n",
    "            if check_data_has_combination_test(d, combination):\n",
    "                sample_X = get_data_from_combination(d, combination)\n",
    "                y = r[i].predict([sample_X])[0]\n",
    "                origin_predicted.append( (test_index, y) )\n",
    "                break\n",
    "        else:\n",
    "            # Just average it\n",
    "            sum = 0\n",
    "            for subject in d:\n",
    "                if subject != 'serial':\n",
    "                    sum += d[subject]\n",
    "            origin_predicted.append((test_index, sum // 4))\n",
    "    \n",
    "    sorted_origin_predicted = sorted(origin_predicted, key = lambda t : t[1])\n",
    "    \n",
    "    # Rescale origin_predicted into predicted\n",
    "    predicted = np.zeros(len(test_data))\n",
    "    \n",
    "    for i, d in enumerate(sorted_origin_predicted):\n",
    "        test_index, _ = d\n",
    "        y = (i * 8) // len(sorted_origin_predicted) + 1\n",
    "        \n",
    "        if y == 1:\n",
    "            y = 2\n",
    "        if y == 8 :\n",
    "            y = 7\n",
    "            \n",
    "        predicted[test_index] = y\n",
    "    \n",
    "    C = 0\n",
    "    W = 0\n",
    "    for predicted_y, y in zip(predicted, test_labels):\n",
    "        if abs(y - predicted_y) <= 1:\n",
    "            C += 1\n",
    "        else:\n",
    "            W += 1\n",
    "    print ( (C - W) * 100 / (C + W) )\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.353947936142674\n"
     ]
    }
   ],
   "source": [
    "predicted = evaluate_2(regressors, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 17383.,   8691.,   8691.,   8692.,   8691.,  17382.]),\n",
       " array([ 2.        ,  2.83333333,  3.66666667,  4.5       ,  5.33333333,\n",
       "         6.16666667,  7.        ]),\n",
       " <a list of 6 Patch objects>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22384fa46d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicted,  6 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a nice score distribution for Math, note that we lump together rank 1 and 2, and together rank 7 and 8.\n",
    "\n",
    "Running this on Hackerank give us a score of 42.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is the full code for a score of 42.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "combinations = ['English, Physics, Chemistry, ComputerScience, Mathematics',\n",
    "'English, Physics, Chemistry, PhysicalEducation, Mathematics',\n",
    "'English, Physics, Chemistry, Economics, Mathematics',\n",
    "'English, Physics, Chemistry, Biology, Mathematics',  \n",
    "'English, Economics, Accountancy, BusinessStudies, Mathematics']\n",
    "\n",
    "combinations = [c.split(', ') for c in combinations]\n",
    "\n",
    "def check_data_has_combination(data, combination):\n",
    "    for subject in combination:\n",
    "        if subject not in data:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def check_data_has_combination_test(data, combination):\n",
    "    for subject in combination:\n",
    "        if subject != 'Mathematics' and subject not in data:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def get_data_from_combination(data, combination):\n",
    "    d = []\n",
    "    for subject in combination:\n",
    "        if subject in data:\n",
    "            d.append(data[subject])\n",
    "    return d\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressors = []\n",
    "# 5 trees for 5 combinations \n",
    "for i in range(5):\n",
    "    #regressors.append(DecisionTreeRegressor(criterion = 'mae', max_depth = 10))\n",
    "    regressors.append(LinearRegression())\n",
    "    \n",
    "TRAINING = 'training.json'\n",
    "\n",
    "# Training data\n",
    "X_s = [[] for _ in range(5)]\n",
    "Y_s = [[] for _ in range(5)]\n",
    "\n",
    "# Load training data\n",
    "with open(TRAINING, 'r') as fh:\n",
    "    lines = fh.readlines()\n",
    "    \n",
    "    for line in lines[1:]:\n",
    "        d = json.loads(line)\n",
    "        \n",
    "        for i, combination in enumerate(combinations):\n",
    "            if check_data_has_combination(d, combination):\n",
    "                sample = get_data_from_combination(d, combination)\n",
    "                X_s[i].append(sample[:4])\n",
    "                Y_s[i].append(sample[4])\n",
    "                break\n",
    "\n",
    "X_s = [np.array(X_s[i]) for i in range(5)]\n",
    "Y_s = [np.array(Y_s[i]) for i in range(5)]\n",
    "\n",
    "for i in range(5):\n",
    "    regressors[i].fit(X_s[i], Y_s[i])\n",
    "    \n",
    "    \n",
    "# Testing over the input data\n",
    "import sys\n",
    "lines = sys.stdin.readlines()\n",
    "\n",
    "origin_predicted = []\n",
    "\n",
    "no_of_test = len(lines[1:])\n",
    "\n",
    "for test_index, line in enumerate(lines[1:]):\n",
    "    d = json.loads(line)\n",
    "\n",
    "    for i, combination in enumerate(combinations):\n",
    "        if check_data_has_combination_test(d, combination):\n",
    "            sample_X = get_data_from_combination(d, combination)\n",
    "            y = regressors[i].predict([sample_X])[0]\n",
    "            origin_predicted.append( (test_index, y) )\n",
    "            break\n",
    "    else:\n",
    "        # Just average it\n",
    "        sum = 0\n",
    "        for subject in d:\n",
    "            if subject != 'serial':\n",
    "                sum += d[subject]\n",
    "        origin_predicted.append( (test_index, sum // 4) )\n",
    "\n",
    "sorted_origin_predicted = sorted(origin_predicted, key = lambda t : t[1])\n",
    "predicted = np.zeros(no_of_test)\n",
    "\n",
    "for i, d in enumerate(sorted_origin_predicted):\n",
    "    test_index, _ = d\n",
    "    y = (i * 8) // len(sorted_origin_predicted) + 1\n",
    "\n",
    "    if y == 1:\n",
    "        y = 2\n",
    "    if y == 8 :\n",
    "        y = 7\n",
    "    \n",
    "    predicted[test_index] = y\n",
    "\n",
    "for i in range(no_of_test):\n",
    "    print (int(predicted[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
